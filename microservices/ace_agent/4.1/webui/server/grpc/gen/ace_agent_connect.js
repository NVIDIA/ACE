//
// Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.
//
// NVIDIA CORPORATION and its licensors retain all intellectual property
// and proprietary rights in and to this software, related documentation
// and any modifications thereto.  Any use, reproduction, disclosure or
// distribution of this software and related documentation without an express
// license agreement from NVIDIA CORPORATION is strictly prohibited.

// @generated by protoc-gen-connect-es v1.4.0
// @generated from file ace_agent.proto (package nvidia.aceagent.chatcontroller.v1, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import { APIStatusResponse, ChatRequest, ChatResponse, EventRequest, EventResponse, GetStatusRequest, GetStatusResponse, PipelineRequest, ReceiveAudioRequest, ReceiveAudioResponse, ReloadSpeechConfigsRequest, SendAudioRequest, SpeechRecognitionControlRequest, StreamingSpeechResultsRequest, StreamingSpeechResultsResponse, SynthesizeSpeechRequest, UserContext, UserContextRequest, UserParametersRequest } from "./ace_agent_pb.js";
import { MethodKind } from "@bufbuild/protobuf";

/**
 *
 * The AceAgentGrpc service provides apis to interact with chat engine and speech
 * components.
 *
 * @generated from service nvidia.aceagent.chatcontroller.v1.AceAgentGrpc
 */
export const AceAgentGrpc = {
  typeName: "nvidia.aceagent.chatcontroller.v1.AceAgentGrpc",
  methods: {
    /**
     * CreatePipeline API is used to create new pipeline with Chat controller,
     *  It acquires a Chat controller pipeline with a unique stream_id populated
     * by the client in PipelineRequest.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.CreatePipeline
     */
    createPipeline: {
      name: "CreatePipeline",
      I: PipelineRequest,
      O: APIStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * FreePipeline API is used to free up a pipeline with Chat controller,
     * created by using CreatePipeline API. Client needs to pass same stream_id
     * in PipelineRequest as used in CreatePipeline.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.FreePipeline
     */
    freePipeline: {
      name: "FreePipeline",
      I: PipelineRequest,
      O: APIStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * SendAudio API is used to stream audio content to ASR from Chat controller.
     * This is a client side streaming API.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.SendAudio
     */
    sendAudio: {
      name: "SendAudio",
      I: SendAudioRequest,
      O: APIStatusResponse,
      kind: MethodKind.ClientStreaming,
    },
    /**
     * ReceiveAudio API is used to receive synthesized audio from TTS through
     * Chat controller. This is a server side streaming API.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.ReceiveAudio
     */
    receiveAudio: {
      name: "ReceiveAudio",
      I: ReceiveAudioRequest,
      O: ReceiveAudioResponse,
      kind: MethodKind.ServerStreaming,
    },
    /**
     * StreamSpeechResults API is used to receive all the meta data from
     * Chat controller like  ASR transcripts, Chat engine responses, Pipeline
     * states etc. This is a broadcasting API i.e it can fan out responses to
     * multiple concurrent client instances using same stream_id.
     * This is a server side streaming API.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.StreamSpeechResults
     */
    streamSpeechResults: {
      name: "StreamSpeechResults",
      I: StreamingSpeechResultsRequest,
      O: StreamingSpeechResultsResponse,
      kind: MethodKind.ServerStreaming,
    },
    /**
     * StartRecognition API is used to start the ASR recognition in Chat
     * controller for the audio content streamed from SendAudio API.
     * This API also provides a flag to mark the ASR recognition as standalone,
     * i.e Chat Engine and TTS will not be invoked for the ASR transcript.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.StartRecognition
     */
    startRecognition: {
      name: "StartRecognition",
      I: SpeechRecognitionControlRequest,
      O: APIStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * StopRecognition API is used to stop the ASR recognition for the audio
     * content streamed from SendAudio API.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.StopRecognition
     */
    stopRecognition: {
      name: "StopRecognition",
      I: SpeechRecognitionControlRequest,
      O: APIStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * This API can be used to set the runtime user parameters like user_id
     * for Chat controller pipeline.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.SetUserParameters
     */
    setUserParameters: {
      name: "SetUserParameters",
      I: UserParametersRequest,
      O: APIStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * GetStatus API can be used to get the latest state of Chat controller pipeline.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.GetStatus
     */
    getStatus: {
      name: "GetStatus",
      I: GetStatusRequest,
      O: GetStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * ReloadSpeechConfigs API can be used to reload the ASR word boosting and
     * TTS Arpbet configs in Chat controller.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.ReloadSpeechConfigs
     */
    reloadSpeechConfigs: {
      name: "ReloadSpeechConfigs",
      I: ReloadSpeechConfigsRequest,
      O: APIStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * SynthesizeSpeech API is used to send text transcript directly to the TTS
     * for standalone TTS audio synthesis.
     * The generated audio will be routed to the path specified in the pipeline
     * graph provided in Chat controller.
     * e.g. if the TTS audio is routed to A2F in the graph, the audio will be
     * sent to A2F server.
     * If the TTS audio is routed to Grpc client then it will be available
     * through the server side streaming ReceiveAudio API.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.SynthesizeSpeech
     */
    synthesizeSpeech: {
      name: "SynthesizeSpeech",
      I: SynthesizeSpeechRequest,
      O: APIStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * GetUserContext API is used to get the current user context from Chat Engine.
     * The API returns a UserContext message containing the current conversation
     * history and any context attached to the active user_id.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.GetUserContext
     */
    getUserContext: {
      name: "GetUserContext",
      I: UserContextRequest,
      O: UserContext,
      kind: MethodKind.Unary,
    },
    /**
     * SetUserContext API is used to set the current user context in Chat Engine.
     * The API accepts a UserContext message containing the conversation
     * history and any context to be attached to the active user_id.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.SetUserContext
     */
    setUserContext: {
      name: "SetUserContext",
      I: UserContext,
      O: APIStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * UpdateUserContext API is used to update the current user context from
     * Chat Engine. The API accepts a UserContext message containing any context
     * to be attached to the active user_id.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.UpdateUserContext
     */
    updateUserContext: {
      name: "UpdateUserContext",
      I: UserContext,
      O: APIStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * DeleteUserContext API is used to delete the current user context attached
     * to a user_id in Chat Engine.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.DeleteUserContext
     */
    deleteUserContext: {
      name: "DeleteUserContext",
      I: UserContextRequest,
      O: APIStatusResponse,
      kind: MethodKind.Unary,
    },
    /**
     * Chat API is used to send text queries to Chat Engine via Chat controller.
     * This API also provides a flag to disable TTS synthesis for the response
     * generated by Chat Engine.
     * This can be used for a text in and text out type of scenario.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.Chat
     */
    chat: {
      name: "Chat",
      I: ChatRequest,
      O: ChatResponse,
      kind: MethodKind.ServerStreaming,
    },
    /**
     * Event API is used to send events to Chat Engine via Chat controller.
     *
     * @generated from rpc nvidia.aceagent.chatcontroller.v1.AceAgentGrpc.Event
     */
    event: {
      name: "Event",
      I: EventRequest,
      O: EventResponse,
      kind: MethodKind.ServerStreaming,
    },
  }
};

