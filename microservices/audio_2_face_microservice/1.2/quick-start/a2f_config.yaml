# SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

common:
  # Determines:
  # * the maximum number of clients connected at the same time
  # * the batch size for the inference
  # This number must be as close as possible to your use-case
  # If it's too low you won't be able to serve all the clients in parallel
  # If it's too high the performance of the service will degrade
  stream_number: 10
  # Adds 1.5 seconds of silence at the end of the audio clip and reset the emotion to neutral
  # This can be useful for specific use-cases
  # E.g.: If you want to make sure that the mouth of all Avatar closes and goes back to neutral
  # after processing the audio clip
  # However we recommend not to use it, to provide more flexibility to clients connecting to the
  # service. As these clients can also take care of sending this silence and neutral emotion
  add-silence-padding-after-audio: false
  # In the current design of the A2F service there are queues in between processing nodes of a
  # specific max-size.
  # So that we have:
  # Streammux => queue-after-streammux => A2E => queue-after-a2e => A2F => queue-after-a2f
  # The maximum number of buffer stored in these queues are controlled here.
  # If you are unsure, you should keep the default config file
  queue-size-after-streammux: 1
  queue-size-after-a2e: 1 
  queue-size-after-a2f: 300
  # Maximum size of the IDs provided in the gRPC header of `a2x-interface`
  max-len-uuid: 50
  # Minimum allowed sample rate
  min-sample-rate: 16000
  # Maximum allowed sample rate
  max-sample-rate: 144000

grpc_input:
  # Input port
  port: 50000
  # Minimum amount of audio FPS that should be provided
  # If the client FPS are too low ( client FPS < `low-fps`)
  # for more than `low-fps-max-duration-second` seconds
  # then A2F Service consider the client as faulty and interrupts
  # the connection as the output streaming quality would be too
  # low.
  low-fps: 29
  low-fps-max-duration-second: 7

grpc_output:
  # Where to connect to send the animation data
  ip: 0.0.0.0
  port: 51000

A2E:
  # Whether to enable A2E
  enabled: true
  # How often to perform A2E inference on the given data
  inference-interval: 10
  # where A2E network is located
  model_path: "/opt/nvidia/a2f_pipeline/a2e_data/data/networks/"
  # Post-processing emotion config
  emotions:
    # Increases the spread between emotion values by pushing them higher or lower.
    # Default value: 1
    # Min: 0.3
    # Max: 3
    emotion_contrast: 1.0
    # Coefficient for smoothing emotions over time
    #  0 means no smoothing at all (can be jittery)
    #  1 means extreme smoothing (emotion values not updated over time)
    # Default value: 0.7
    # Min: 0
    # Max: 1
    live_blend_coef: 0.7
    # Sets the strength of the preferred emotions (passed as input) relative to emotions detected by A2E.
    # 0 means only A2E output will be used for emotion rendering.
    # 1 means only the preferred emotions will be used for emotion rendering.
    # Default value: 0.5
    # Min: 0
    # Max: 1
    preferred_emotion_strength: 0.5
    # Activate blending between the preferred emotions (passed as input) and the emotions detected by A2E.
    # Default: True
    enable_preferred_emotion: true
    # Sets the strength of generated emotions relative to neutral emotion.
    # This multiplier is applied globally after the mix of emotion is done.
    # If set to 0, emotion will be neutral.
    # If set to 1, the blend of emotion will be fully used. (can be too intense)
    # Default value: 0.6
    # Min: 0
    # Max: 1
    emotion_strength: 0.6
    # Sets a firm limit on the quantity of emotion sliders engaged by A2E
    # emotions with the highest weight will be prioritized
    # Default value: 3
    # Min: 1
    # Max: 6
    max_emotions: 3


A2F:
  # A2F model path to use, that's a path internal to the docker container
  model_path: "/opt/nvidia/a2f_pipeline/a2f_data/data/networks/claire_v1.3"
  # Default multiplier to apply to the blendshape output of A2F
  api:
    bs_weight_multipliers: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
